#!/bin/sh
#/ Usage: ghe-s3-backup-all
#/ Take snapshots of all GitHub Enterprise data, including the mysql database
#/ and backup to S3.
set -e

# Bring in the backup configuration
cd $(dirname "$0")/../..
. share/github-backup-utils/ghe-backup-config

# Run the backup script.
ghe-backup

# Create the bucket if it doesn't exist.
aws s3 mb s3://$GHE_S3_BUCKET

# compress the data
cd "$GHE_DATA_DIR"/current
TAR_FILENAME=$(readlink ../current)".tar.gz"
# split file to maximum 5 GB size
tar czvf - * | split -b 5G -d - $TAR_FILENAME"."

# check how many compressed files need to upload
TAR_FILES=($(ls $TAR_FILENAME*))

# Upload to S3.
S3_SSE_C_KEY=$(cat "$S3_AES256_KEY_FILE")

for file in ${TAR_FILES[@]}; do
  echo "upload file: $file"
  aws s3api put-object --sse-customer-algorithm AES256 --sse-customer-key $S3_SSE_C_KEY --bucket $GHE_S3_BUCKET --key $file --body $file
done
